{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "NUM_STATES = 10\n",
    "NUM_ACTIONS = 2\n",
    "Gamma = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define one-hot function that returns a state's index to a one-hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_state(index):\n",
    "    array = np.zeros(NUM_STATES)\n",
    "    array[index] = 1.\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define state's reward, if index = 4, reward = 1, else =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state's reward vect: [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "state_reward = np.zeros(NUM_STATES)\n",
    "state_reward[4] = 1.\n",
    "print(\"state's reward vect:\", state_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Deep Q learning we try to minimize the difference between Qtarget and Qprediction. Now we create 2 layer NN, with input's size =  NUM_STATES and output's size = NUM_ACTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "state = tf.placeholder(\"float\", [None, NUM_STATES])\n",
    "Qtarget = tf.placeholder(\"float\", [None, NUM_ACTIONS])\n",
    "#Qtarget is the targeted Q-value of actions\n",
    "\n",
    "hidden_weights = tf.Variable(tf.constant(0., shape = [NUM_STATES,NUM_ACTIONS]))\n",
    "\n",
    "Qprediction = tf.matmul(state,hidden_weights)\n",
    "#Qprediction is the predicted Q-value of actions\n",
    "\n",
    "loss  = tf.reduce_mean(tf.square(Qprediction - Qtarget  ))\n",
    "train_operation = tf.train.AdamOptimizer(0.1).minimize(loss)\n",
    "\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.099999368190765381, 0.099999688565731049, 0.099999800324440002, 0.099999897181987762, 1.0999998673796654, 0.099999897181987762, 0.099999904632568359, 0.099999919533729553, 0.09999992698431015, 0.0]\n",
      "[0.19881114363670349, 0.1995868980884552, 0.19976025819778442, 0.19989678263664246, 1.1998722553253174, 0.19989678263664246, 0.19991345703601837, 0.19992552697658539, 0.19993466138839722, 0.074408724904060364]\n",
      "[0.29512625932693481, 0.29841196537017822, 0.29909563064575195, 0.2996172308921814, 1.29952472448349, 0.2996172308921814, 0.29967981576919556, 0.29972493648529053, 0.29975897073745728, 0.15470406413078308]\n",
      "[0.3870815634727478, 0.39605873823165894, 0.39779916405677795, 0.39908486604690552, 1.3988598883152008, 0.39908486604690552, 0.39923638105392456, 0.39934521913528442, 0.39942705631256104, 0.21525681018829346]\n",
      "[0.47218221426010132, 0.49203377962112427, 0.4956396222114563, 0.49821865558624268, 1.4977733790874481, 0.49821865558624268, 0.49851709604263306, 0.49873062968254089, 0.49889081716537476, 0.25007086992263794]\n",
      "[0.54742807149887085, 0.58576059341430664, 0.59236115217208862, 0.59693413972854614, 1.5961551070213318, 0.59693413972854614, 0.59745365381240845, 0.59782397747039795, 0.59810101985931396, 0.27951481938362122]\n",
      "[0.60978573560714722, 0.67657619714736938, 0.68768268823623657, 0.69514381885528564, 1.6938896179199219, 0.69514381885528564, 0.69597595930099487, 0.69656693935394287, 0.69700783491134644, 0.31997713446617126]\n",
      "[0.65694350004196167, 0.76373308897018433, 0.78129655122756958, 0.79275631904602051, 1.7908551692962646, 0.79275631904602051, 0.79401129484176636, 0.7948993444442749, 0.79556006193161011, 0.37319761514663696]\n",
      "[0.68794971704483032, 0.84641218185424805, 0.87286925315856934, 0.88967710733413696, 1.8869245052337646, 0.88967710733413696, 0.89148497581481934, 0.89275968074798584, 0.89370548725128174, 0.43428021669387817]\n",
      "[0.70332193374633789, 0.92374765872955322, 0.96204346418380737, 0.98580890893936157, 1.9819653034210205, 0.98580890893936157, 0.98832076787948608, 0.99008560180664063, 0.99139153957366943, 0.49631196260452271]\n",
      "[0.7046583890914917, 0.99486547708511353, 1.0484399795532227, 1.081051230430603, 2.0758397579193115, 1.081051230430603, 1.0844404697418213, 1.0868134498596191, 1.0885646343231201, 0.55149561166763306]\n",
      "[0.69411331415176392, 1.0589350461959839, 1.1316624879837036, 1.1753010749816895, 2.1684055328369141, 1.1753010749816895, 1.1797642707824707, 1.1828784942626953, 1.1851706504821777, 0.59614259004592896]\n",
      "[0.67400979995727539, 1.1152282953262329, 1.2113039493560791, 1.2684533596038818, 2.2595163583755493, 1.2684533596038818, 1.2742114067077637, 1.2782156467437744, 1.2811553478240967, 0.63401079177856445]\n",
      "[0.6466442346572876, 1.1631771326065063, 1.2869546413421631, 1.3604006767272949, 2.3490220308303833, 1.3604006767272949, 1.3676997423171997, 1.3727588653564453, 1.376463770866394, 0.67239338159561157]\n",
      "[0.61422348022460938, 1.2024190425872803, 1.3582119941711426, 1.4510344266891479, 2.4367698431015015, 1.4510344266891479, 1.460146427154541, 1.4664419889450073, 1.4710410833358765, 0.71656709909439087]\n",
      "[0.57886242866516113, 1.2328232526779175, 1.424691915512085, 1.5402445793151855, 2.5226049423217773, 1.5402445793151855, 1.5514677762985229, 1.5591983795166016, 1.564832329750061, 0.76732516288757324]\n",
      "[0.5425911545753479, 1.2544928789138794, 1.4860415458679199, 1.6279205083847046, 2.6063718795776367, 1.6279205083847046, 1.6415801048278809, 1.6509613990783691, 1.6577826738357544, 0.82193595170974731]\n",
      "[0.50734138488769531, 1.2677464485168457, 1.5419512987136841, 1.7139512300491333, 2.6879152059555054, 1.7139512300491333, 1.7303992509841919, 1.7416644096374512, 1.7498372793197632, 0.87569659948348999]\n",
      "[0.47489738464355469, 1.273085355758667, 1.5921671390533447, 1.7982264757156372, 2.7670812606811523, 1.7982264757156372, 1.8178417682647705, 1.831241250038147, 1.8409420251846313, 0.92406225204467773]\n",
      "[0.49885982275009155, 1.2711540460586548, 1.6365005970001221, 1.8806366920471191, 2.8437188863754272, 1.8806366920471191, 1.9038245677947998, 1.9196262359619141, 1.9310430288314819, 0.96570837497711182]\n",
      "[0.53415888547897339, 1.2627013921737671, 1.6748365163803101, 1.9610742330551147, 2.9176818132400513, 1.9610742330551147, 1.9882656335830688, 2.0067543983459473, 2.0200870037078857, 1.0034799575805664]\n",
      "[0.55137848854064941, 1.2485460042953491, 1.7071375846862793, 2.0394337177276611, 2.988829493522644, 2.0394337177276611, 2.0710840225219727, 2.0925614833831787, 2.1080217361450195, 1.0420136451721191]\n",
      "[0.55394190549850464, 1.2295485734939575, 1.7334457635879517, 2.1156127452850342, 3.0570290088653564, 2.1156127452850342, 2.1522006988525391, 2.1769847869873047, 2.1947956085205078, 1.0845143795013428]\n",
      "[0.55136269330978394, 1.2065901756286621, 1.7538802623748779, 2.1895129680633545, 3.1221568584442139, 2.1895129680633545, 2.2315385341644287, 2.2599625587463379, 2.2803583145141602, 1.1311110258102417]\n",
      "[0.55501860380172729, 1.1805559396743774, 1.7686331272125244, 2.2610404491424561, 3.1841003894805908, 2.2610404491424561, 2.3090231418609619, 2.3414349555969238, 2.3646605014801025, 1.1792258024215698]\n",
      "[0.57249081134796143, 1.1523218154907227, 1.7779620885848999, 2.3301067352294922, 3.2427597045898438, 2.3301067352294922, 2.3845827579498291, 2.4213438034057617, 2.4476544857025146, 1.225081205368042]\n",
      "[0.60370206832885742, 1.1227437257766724, 1.7821824550628662, 2.3966295719146729, 3.2980484962463379, 2.3966295719146729, 2.458148717880249, 2.4996330738067627, 2.5292935371398926, 1.266014575958252]\n",
      "[0.64309233427047729, 1.0926463603973389, 1.7816579341888428, 2.4605333805084229, 3.3498961925506592, 2.4605333805084229, 2.5296561717987061, 2.5762488842010498, 2.6095328330993652, 1.302377462387085]\n",
      "[0.6821557879447937, 1.0628120899200439, 1.7767914533615112, 2.5217504501342773, 3.3982484340667725, 2.5217504501342773, 2.5990443229675293, 2.6511397361755371, 2.6883294582366943, 1.3371332883834839]\n",
      "[0.71211302280426025, 1.0339692831039429, 1.76801598072052, 2.5802211761474609, 3.4430685043334961, 2.5802211761474609, 2.6662566661834717, 2.7242569923400879, 2.7656416893005371, 1.373548150062561]\n",
      "[0.72881650924682617, 1.0067793130874634, 1.7557861804962158, 2.6358950138092041, 3.4843375682830811, 2.6358950138092041, 2.7312414646148682, 2.7955548763275146, 2.8414304256439209, 1.4129682779312134]\n",
      "[0.73489642143249512, 0.98182404041290283, 1.7405704259872437, 2.6887307167053223, 3.5220556259155273, 2.6887307167053223, 2.7939522266387939, 2.8649907112121582, 2.9156584739685059, 1.4541571140289307]\n",
      "[0.73725825548171997, 0.95959377288818359, 1.7228440046310425, 2.7386970520019531, 3.556241512298584, 2.7386970520019531, 2.8543477058410645, 2.9325249195098877, 2.9882903099060059, 1.4942454099655151]\n",
      "[0.74344158172607422, 0.94047755002975464, 1.7030822038650513, 2.7857730388641357, 3.5869326591491699, 2.7857730388641357, 2.9123923778533936, 2.9981215000152588, 3.0592935085296631, 1.5306882858276367]\n",
      "[0.75797957181930542, 0.92475599050521851, 1.6817548274993896, 2.8299481868743896, 3.6141848564147949, 2.8299481868743896, 2.9680571556091309, 3.0617480278015137, 3.1286375522613525, 1.5631200075149536]\n",
      "[0.78069847822189331, 0.91259807348251343, 1.6593208312988281, 2.8712227344512939, 3.6380710601806641, 2.8712227344512939, 3.0213184356689453, 3.1233758926391602, 3.1962945461273193, 1.5935319662094116]\n",
      "[0.8078773021697998, 0.90406173467636108, 1.6362230777740479, 2.9096078872680664, 3.6586816310882568, 2.9096078872680664, 3.0721595287322998, 3.1829805374145508, 3.2622389793395996, 1.6246063709259033]\n",
      "[0.83445239067077637, 0.89909845590591431, 1.6128838062286377, 2.9451258182525635, 3.6761221885681152, 2.9451258182525635, 3.1205699443817139, 3.2405409812927246, 3.3264479637145996, 1.6576859951019287]\n",
      "[0.85626763105392456, 0.89756119251251221, 1.5897003412246704, 2.9778087139129639, 3.6905131340026855, 2.9778087139129639, 3.1665458679199219, 3.2960407733917236, 3.3889017105102539, 1.6919155120849609]\n",
      "[0.87170159816741943, 0.89921534061431885, 1.5670408010482788, 3.0076994895935059, 3.7019875049591064, 3.0076994895935059, 3.210090160369873, 3.3494677543640137, 3.4495830535888672, 1.724992036819458]\n",
      "[0.8817785382270813, 0.90375161170959473, 1.5452407598495483, 3.03485107421875, 3.7106902599334717, 3.03485107421875, 3.2512123584747314, 3.4008135795593262, 3.5084774494171143, 1.7549382448196411]\n",
      "[0.88907885551452637, 0.91080003976821899, 1.5245994329452515, 3.0593256950378418, 3.7167763710021973, 3.0593256950378418, 3.289928674697876, 3.4500746726989746, 3.5655734539031982, 1.781639575958252]\n",
      "[0.89648163318634033, 0.9199448823928833, 1.5053775310516357, 3.0811946392059326, 3.7204089164733887, 3.0811946392059326, 3.3262617588043213, 3.4972512722015381, 3.6208622455596924, 1.8068348169326782]\n",
      "[0.90627163648605347, 0.93073934316635132, 1.4877945184707642, 3.1005377769470215, 3.7217578887939453, 3.1005377769470215, 3.3602402210235596, 3.5423483848571777, 3.6743381023406982, 1.8325974941253662]\n",
      "[0.91962134838104248, 0.94272053241729736, 1.4720274209976196, 3.1174423694610596, 3.7209985256195068, 3.1174423694610596, 3.3918993473052979, 3.5853750705718994, 3.7259984016418457, 1.8596689701080322]\n",
      "[0.93631839752197266, 0.95542359352111816, 1.4582098722457886, 3.1320028305053711, 3.7183096408843994, 3.1320028305053711, 3.4212801456451416, 3.6263444423675537, 3.7758429050445557, 1.8869705200195313]\n",
      "[0.95472967624664307, 0.9683951735496521, 1.4464324712753296, 3.1443195343017578, 3.7138721942901611, 3.1443195343017578, 3.4484293460845947, 3.6652741432189941, 3.8238747119903564, 1.9125722646713257]\n",
      "[0.97217881679534912, 0.98120611906051636, 1.4367433786392212, 3.1544985771179199, 3.7078676223754883, 3.1544985771179199, 3.4733986854553223, 3.7021856307983398, 3.8700997829437256, 1.9353203773498535]\n",
      "[0.98594510555267334, 0.99346286058425903, 1.429149866104126, 3.1626505851745605, 3.7004764080047607, 3.1626505851745605, 3.4962453842163086, 3.7371044158935547, 3.9145267009735107, 1.9557714462280273]\n",
      "[0.99468433856964111, 1.0048173666000366, 1.4236207008361816, 3.1688899993896484, 3.6918773651123047, 3.1688899993896484, 3.5170307159423828, 3.7700595855712891, 3.9571671485900879, 1.9756152629852295]\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    state_batch = []\n",
    "    reward_batch = []\n",
    "    \n",
    "    # create a batch of states (input) and a batch of reward (Qtarget/output) for trainning\n",
    "    for state_index in range(NUM_STATES):\n",
    "        state_batch.append(one_hot_state(state_index))\n",
    "        \n",
    "        #all possible new state s'\n",
    "        go_left_index = (state_index - 1) % NUM_STATES\n",
    "        go_right_index = (state_index + 1) % NUM_STATES\n",
    "        \n",
    "        #compute the pred value of Q(s',a') for all posible s' and a'\n",
    "        go_left_Qval = session.run(Qprediction, feed_dict={state: [one_hot_state(go_left_index)]})[0]\n",
    "        go_right_Qval = session.run(Qprediction, feed_dict={state: [one_hot_state(go_right_index)]})[0]\n",
    "        \n",
    "        #Qtarget(s') = rew + gamma* max Q(s',a') /over a'\n",
    "        target_rew = [state_reward[go_left_index] + Gamma*np.max(go_left_Qval),\n",
    "                     state_reward[go_right_index] +  Gamma*np.max(go_right_index)]\n",
    "        \n",
    "        reward_batch.append(target_rew)\n",
    "    \n",
    "    #start train linear model\n",
    "    session.run(train_operation,\n",
    "               feed_dict= {state: state_batch, Qtarget: reward_batch})\n",
    "    \n",
    "    #print out the learned result\n",
    "    print([state_reward[x] + np.max(session.run(Qprediction, feed_dict={state: [one_hot_state(x)]}))\n",
    "           for x in range(NUM_STATES)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.014880333840847016, 0.03991737961769104, 1.014880333840847, 0.03991737961769104, 0.014880333840847016, 0.0, 0.0, 0.0]\n",
      "[0.0074131056666374212, 0.0077257268130779266, 0.041042417287826538, 0.2138674020767212, 1.0410424172878265, 0.2138674020767212, 0.041042417287826538, 0.0077257268130779266, 0.0074131056666374212, 0.0074364297091960912]\n",
      "[0.0077425584197044379, 0.0081842511892318733, 0.054672271013259888, 0.2606968879699707, 1.0546722710132599, 0.2606968879699707, 0.054672271013259888, 0.0081842511892318733, 0.0077425584197044379, 0.0031552545726299288]\n",
      "[0.0059305492788553245, 0.0069371566176414491, 0.040653026103973394, 0.20981717109680176, 1.0406530261039735, 0.20981717109680176, 0.040653026103973394, 0.0069371566176414491, 0.0059305492788553245, 0.0013544321991503239]\n",
      "[0.0042029205709695821, 0.0057020824402570728, 0.038462829589843754, 0.18911731243133545, 1.0384628295898437, 0.18911731243133545, 0.038462829589843754, 0.0057020824402570728, 0.0042029205709695821, 0.00084759956225752839]\n",
      "[0.0025720680132508278, 0.008003775030374527, 0.041582995653152467, 0.21039748191833496, 1.0415829956531524, 0.21039748191833496, 0.041582995653152467, 0.008003775030374527, 0.0025720680132508278, -0.00039172135293483737]\n",
      "[0.0001598525792360306, 0.008978532254695892, 0.043164810538291937, 0.21471731662750246, 1.043164810538292, 0.21471731662750246, 0.043164810538291937, 0.008978532254695892, 0.0001598525792360306, 6.7305308766663083e-05]\n",
      "[0.0025517962872982029, 0.0083725534379482276, 0.041209730505943301, 0.20547406673431398, 1.0412097305059433, 0.20547406673431398, 0.041209730505943301, 0.0083725534379482276, 0.0025517962872982029, 0.00052237715572118766]\n",
      "[0.0025408215820789341, 0.0080926716327667236, 0.041394129395484924, 0.20728247165679933, 1.0413941293954849, 0.20728247165679933, 0.041394129395484924, 0.0080926716327667236, 0.0025408215820789341, 0.00071896663866937165]\n",
      "[0.00099104130640625954, 0.0084923885762691505, 0.041912823915481567, 0.20984640121459963, 1.0419128239154816, 0.20984640121459963, 0.041912823915481567, 0.0084923885762691505, 0.00099104130640625954, 1.3228016905486584e-05]\n",
      "[0.0017663117498159409, 0.0083169527351856232, 0.041528680920600893, 0.2078561544418335, 1.0415286809206008, 0.2078561544418335, 0.041528680920600893, 0.0083169527351856232, 0.0017663117498159409, 0.00040710438042879105]\n",
      "[0.0017822477966547012, 0.0083192326128482819, 0.04159756898880005, 0.20810563564300538, 1.0415975689888, 0.20810563564300538, 0.04159756898880005, 0.0083192326128482819, 0.0017822477966547012, 0.00040676100179553036]\n",
      "[0.0015458431094884874, 0.0083587542176246643, 0.041718119382858278, 0.20864996910095215, 1.0417181193828582, 0.20864996910095215, 0.041718119382858278, 0.0083587542176246643, 0.0015458431094884874, 0.00028640795499086381]\n",
      "[0.0017415348440408707, 0.0083272054791450507, 0.041626957058906559, 0.20818440914154054, 1.0416269570589065, 0.20818440914154054, 0.041626957058906559, 0.0083272054791450507, 0.0017415348440408707, 0.00037411537487059833]\n",
      "[0.0016270030289888384, 0.0083318367600440976, 0.041664981842041017, 0.20833868980407716, 1.0416649818420409, 0.20833868980407716, 0.041664981842041017, 0.0083318367600440976, 0.0016270030289888384, 0.00031890191603451968]\n",
      "[0.0016857264563441277, 0.0083392366766929637, 0.041678088903427127, 0.20837972164154053, 1.0416780889034272, 0.20837972164154053, 0.041678088903427127, 0.0083392366766929637, 0.0016857264563441277, 0.0003430268028751016]\n",
      "[0.0016571599990129471, 0.0083275705575943, 0.041660007834434513, 0.20829272270202637, 1.0416600078344345, 0.20829272270202637, 0.041660007834434513, 0.0083275705575943, 0.0016571599990129471, 0.00033011469058692456]\n",
      "[0.0016728091984987261, 0.0083354867994785316, 0.041670086979866031, 0.20835292339324951, 1.0416700869798661, 0.20835292339324951, 0.041670086979866031, 0.0083354867994785316, 0.0016728091984987261, 0.00033590500243008137]\n",
      "[0.0016628460958600046, 0.0083339415490627285, 0.041665488481521608, 0.2083294153213501, 1.0416654884815215, 0.2083294153213501, 0.041665488481521608, 0.0083339415490627285, 0.0016628460958600046, 0.00033114131074398758]\n",
      "[0.0016671057790517809, 0.0083323925733566288, 0.041666463017463684, 0.20833039283752441, 1.0416664630174637, 0.20833039283752441, 0.041666463017463684, 0.0083323925733566288, 0.0016671057790517809, 0.00033353480976074936]\n",
      "[0.0016686948016285898, 0.0083334609866142269, 0.04166729748249054, 0.20833742618560791, 1.0416672974824905, 0.20833742618560791, 0.04166729748249054, 0.0083334609866142269, 0.0016686948016285898, 0.00033445125445723538]\n",
      "[0.0016652107238769533, 0.0083334237337112423, 0.041666141152381903, 0.2083303213119507, 1.041666141152382, 0.2083303213119507, 0.041666141152381903, 0.0083334237337112423, 0.0016652107238769533, 0.00033258334733545782]\n",
      "[0.0016663696616888047, 0.0083335079252719879, 0.041666951775550846, 0.20833497047424318, 1.0416669517755508, 0.20833497047424318, 0.041666951775550846, 0.0083335079252719879, 0.0016663696616888047, 0.00033316696062684063]\n",
      "[0.0016671733930706978, 0.0083332426846027385, 0.041666561365127565, 0.20833268165588381, 1.0416665613651275, 0.20833268165588381, 0.041666561365127565, 0.0083332426846027385, 0.0016671733930706978, 0.00033359667286276818]\n",
      "[0.0016667408868670465, 0.0083332903683185581, 0.041666662693023687, 0.20833346843719483, 1.0416666626930238, 0.20833346843719483, 0.041666662693023687, 0.0083332903683185581, 0.0016667408868670465, 0.00033336177002638582]\n",
      "[0.0016665630042552949, 0.00833330824971199, 0.041666710376739503, 0.20833342075347902, 1.0416667103767394, 0.20833342075347902, 0.041666710376739503, 0.00833330824971199, 0.0016665630042552949, 0.00033329473808407784]\n",
      "[0.0016666540876030924, 0.0083333261311054237, 0.041666635870933534, 0.20833320617675782, 1.0416666358709334, 0.20833320617675782, 0.041666635870933534, 0.0083333261311054237, 0.0016666540876030924, 0.00033332409802824261]\n",
      "[0.0016667019575834275, 0.0083333455026149746, 0.041666680574417116, 0.20833344459533693, 1.041666680574417, 0.20833344459533693, 0.041666680574417116, 0.0083333455026149746, 0.0016667019575834275, 0.00033335334155708556]\n",
      "[0.0016666812822222711, 0.0083333298563957221, 0.041666659712791446, 0.20833325386047363, 1.0416666597127915, 0.20833325386047363, 0.041666659712791446, 0.0083333298563957221, 0.0016666812822222711, 0.0003333370201289654]\n",
      "[0.0016666579991579057, 0.0083333350718021396, 0.041666668653488163, 0.20833334922790528, 1.0416666686534881, 0.20833334922790528, 0.041666668653488163, 0.0083333350718021396, 0.0016666579991579057, 0.00033332901075482373]\n",
      "[0.0016666539013385773, 0.0083333350718021396, 0.041666668653488163, 0.20833332538604737, 1.0416666686534881, 0.20833332538604737, 0.041666668653488163, 0.0083333350718021396, 0.0016666539013385773, 0.00033332917373627427]\n",
      "[0.0016666570678353311, 0.0083333358168602, 0.041666665673255922, 0.20833332538604737, 1.0416666656732558, 0.20833332538604737, 0.041666665673255922, 0.0083333358168602, 0.0016666570678353311, 0.00033332707826048139]\n",
      "[0.0016666607931256296, 0.0083333343267440792, 0.041666665673255922, 0.20833332538604737, 1.0416666656732558, 0.20833332538604737, 0.041666665673255922, 0.0083333343267440792, 0.0016666607931256296, 0.0003333304775878787]\n",
      "[0.0016666635870933534, 0.0083333328366279602, 0.041666665673255922, 0.20833332538604737, 1.0416666656732558, 0.20833332538604737, 0.041666665673255922, 0.0083333328366279602, 0.0016666635870933534, 0.00033333215396851306]\n",
      "[0.0016666648909449578, 0.0083333335816860206, 0.041666665673255922, 0.20833332538604737, 1.0416666656732558, 0.20833332538604737, 0.041666665673255922, 0.0083333335816860206, 0.0016666648909449578, 0.00033333261962980036]\n",
      "[0.0016666663810610772, 0.0083333328366279602, 0.041666665673255922, 0.20833332538604737, 1.0416666656732558, 0.20833332538604737, 0.041666665673255922, 0.0083333328366279602, 0.0016666663810610772, 0.00033333336468786004]\n",
      "[0.0016666660085320473, 0.0083333335816860206, 0.041666665673255922, 0.20833332538604737, 1.0416666656732558, 0.20833332538604737, 0.041666665673255922, 0.0083333335816860206, 0.0016666660085320473, 0.00033333301544189456]\n",
      "[0.001666666753590107, 0.0083333328366279602, 0.041666665673255922, 0.20833332538604737, 1.0416666656732558, 0.20833332538604737, 0.041666665673255922, 0.0083333328366279602, 0.001666666753590107, 0.00033333352766931059]\n",
      "[0.0016666661947965624, 0.0083333335816860206, 0.041666665673255922, 0.20833332538604737, 1.0416666656732558, 0.20833332538604737, 0.041666665673255922, 0.0083333335816860206, 0.0016666661947965624, 0.00033333301544189456]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0016666665673255921, 0.0083333328366279602, 0.041666665673255922, 0.20833332538604737, 1.0416666656732558, 0.20833332538604737, 0.041666665673255922, 0.0083333328366279602, 0.0016666665673255921, 0.00033333336468786004]\n",
      "[0.0016666660085320473, 0.0083333335816860206, 0.041666665673255922, 0.20833332538604737, 1.0416666656732558, 0.20833332538604737, 0.041666665673255922, 0.0083333335816860206, 0.0016666660085320473, 0.00033333294559270146]\n",
      "[0.001666666753590107, 0.0083333328366279602, 0.041666668653488163, 0.20833332538604737, 1.0416666686534881, 0.20833332538604737, 0.041666668653488163, 0.0083333328366279602, 0.001666666753590107, 0.00033333345782011748]\n",
      "[0.0016666682437062265, 0.0083333328366279602, 0.041666665673255922, 0.20833332538604737, 1.0416666656732558, 0.20833332538604737, 0.041666665673255922, 0.0083333328366279602, 0.0016666682437062265, 0.00033333455212414265]\n",
      "[0.001666667126119137, 0.0083333320915699016, 0.041666662693023687, 0.20833332538604737, 1.0416666626930238, 0.20833332538604737, 0.041666662693023687, 0.0083333320915699016, 0.001666667126119137, 0.00033333387691527607]\n",
      "[0.001666664145886898, 0.0083333328366279602, 0.041666668653488163, 0.20833332538604737, 1.0416666686534881, 0.20833332538604737, 0.041666668653488163, 0.0083333328366279602, 0.001666664145886898, 0.00033333196770399812]\n",
      "[0.001666664518415928, 0.0083333343267440792, 0.041666665673255922, 0.20833332538604737, 1.0416666656732558, 0.20833332538604737, 0.041666665673255922, 0.0083333343267440792, 0.001666664518415928, 0.00033333252649754287]\n",
      "[0.0016666689887642862, 0.0083333335816860206, 0.041666662693023687, 0.20833332538604737, 1.0416666626930238, 0.20833332538604737, 0.041666662693023687, 0.0083333335816860206, 0.0016666689887642862, 0.00033333441242575649]\n",
      "[0.0016666682437062265, 0.0083333320915699016, 0.041666668653488163, 0.20833332538604737, 1.0416666686534881, 0.20833332538604737, 0.041666668653488163, 0.0083333320915699016, 0.0016666682437062265, 0.00033333355095237498]\n",
      "[0.0016666665673255921, 0.0083333335816860206, 0.041666665673255922, 0.20833332538604737, 1.0416666656732558, 0.20833332538604737, 0.041666665673255922, 0.0083333335816860206, 0.0016666665673255921, 0.00033333445899188521]\n",
      "[0.0016666656360030175, 0.0083333335816860206, 0.041666662693023687, 0.20833332538604737, 1.0416666626930238, 0.20833332538604737, 0.041666662693023687, 0.0083333335816860206, 0.0016666656360030175, 0.00033333222381770611]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "NUM_STATES = 10\n",
    "NUM_ACTIONS = 2\n",
    "Gamma = 0.2\n",
    "\n",
    "def one_hot_state(index):\n",
    "    array = np.zeros(NUM_STATES)\n",
    "    array[index] = 1.\n",
    "    return array\n",
    "\n",
    "state_reward = [(x == 4) for x in range(NUM_STATES)]\n",
    "\n",
    "session = tf.Session()\n",
    "state = tf.placeholder(\"float\", [None, NUM_STATES])\n",
    "Qtarget = tf.placeholder(\"float\", [None, NUM_ACTIONS])\n",
    "#Qtarget is the targeted Q-value of actions\n",
    "\n",
    "hidden_weights = tf.Variable(tf.constant(0., shape=[NUM_STATES, NUM_ACTIONS]))\n",
    "\n",
    "Qprediction = tf.matmul(state,hidden_weights)\n",
    "#Qprediction is the predicted Q-value of actions\n",
    "\n",
    "loss  = tf.reduce_mean(tf.square(Qprediction - Qtarget  ))\n",
    "train_operation = tf.train.AdamOptimizer(0.1).minimize(loss)\n",
    "\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(500):\n",
    "    state_batch = []\n",
    "    reward_batch = []\n",
    "    \n",
    "    # create a batch of states (input) and a batch of reward (Qtarget/output) for trainning\n",
    "    for state_index in range(NUM_STATES):\n",
    "        state_batch.append(one_hot_state(state_index))\n",
    "        \n",
    "        #all possible new state s'\n",
    "        go_left_index = (state_index - 1) % NUM_STATES\n",
    "        go_right_index = (state_index + 1) % NUM_STATES\n",
    "        \n",
    "        #compute the pred value of Q(s',a') for all posible s' and a'\n",
    "        go_left_Qval = session.run(Qprediction, feed_dict={state: [one_hot_state(go_left_index)]})[0]\n",
    "        go_right_Qval = session.run(Qprediction, feed_dict={state: [one_hot_state(go_right_index)]})[0]\n",
    "        #go_left_Qval = session.run(Qprediction, feed_dict={state: [one_hot_state(go_left_index)]})\n",
    "      \n",
    "        #go_right_Qval = session.run(Qprediction, feed_dict={state: [one_hot_state(go_right_index)]})\n",
    "        \n",
    "        #Qtarget(s,a) = rew + gamma* max Q(s',a') /over a'\n",
    "        target_rew = [state_reward[go_left_index] + Gamma*np.max(go_left_Qval),\n",
    "                     state_reward[go_right_index] +  Gamma*np.max(go_right_Qval)]\n",
    "        \n",
    "        reward_batch.append(target_rew)\n",
    "    \n",
    "    #start train linear model\n",
    "    session.run(train_operation,\n",
    "               feed_dict= {state: state_batch, Qtarget: reward_batch})\n",
    "    \n",
    "    #print out the learned result\n",
    "    if i % 10 == 1:\n",
    "        print([state_reward[x] + Gamma*np.max(session.run(Qprediction, feed_dict={state: [one_hot_state(x)]}))\n",
    "           for x in range(NUM_STATES)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
